<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>AsirAbrar</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css">

  <!-- Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">

</head>

<body class="index-page">

  <header id="header" class="header dark-background d-flex flex-column">
    <i class="header-toggle d-xl-none bi bi-list"></i>



    <a href="index.html" class="logo d-flex align-items-center justify-content-center">
      <!-- Uncomment the line below if you also wish to use an image logo -->
      <!-- <img src="assets/img/logo.png" alt=""> -->
      <h1 class="sitename text-center">Asir Abrar</h1>
      <div class="download-cv-wrapper text-center">
        <a href="assets/cv/asir-abrar-cv.pdf" class="download-cv-btn" download>
          <i class="bi bi-download"></i> Download CV
        </a>
      </div>
    </a>


    <nav id="navmenu" class="navmenu">
      <ul>
        <li><a href="#hero" class="active"><i class="bi bi-person navicon"></i> About</a></li>
        <li><a href="#education"><i class="bi bi-mortarboard navicon"></i> Education</a></li>
        <li><a href="#experience"><i class="bi bi-check2-circle navicon"></i> Experience</a></li>
        <li><a href="#research"><i class="bi bi-journals navicon"></i> Research</a></li>
        <li><a href="#paper"><i class="bi bi-file-earmark-text navicon"></i> Papers</a></li>
        <li><a href="#award"><i class="bi bi-award navicon"></i> Awards</a></li>

        <!--
        <li><a href="#portfolio"><i class="bi bi-images navicon"></i> Portfolio</a></li>
        <li><a href="#services"><i class="bi bi-hdd-stack navicon"></i> Services</a></li>

        <li><a href="#contact"><i class="bi bi-envelope navicon"></i> Contact</a></li>-->
      </ul>
    </nav>

  </header>

  <main class="main">

    <!-- Hero Section -->
    <section id="hero" class="hero">
      <div class="hero-container">
        <div class="hero-text">
          <h1>Asir Abrar</h1>

          <p style="color: #444;">
            I’m a <strong>Ph.D. student in Computer Science</strong> at
            <span style="color: #007018; font-weight: 600;">
              Missouri University of Science and Technology
            </span>,
            with a research focus on <strong>cognitive workload assessment</strong>.
            My work integrates <strong>neuroscience</strong> and
            <strong>artificial intelligence</strong>, aiming to model human mental
            states using multimodal data.
          </p>

          <p style="color: #444;">
            <strong>Research Interests:</strong>
            <em>Neuromorphic Computing</em>,
            <em>Brain–Computer Interface</em>,
            <em>Cognitive Modelling</em>
          </p>
        </div>
        <div class="hero-image">
          <img src="AsirAbrar.png" alt="Asir Abrar" class="hero-img-circle">
        </div>
      </div>
    </section>
    <!-- /Hero Section -->




    <!-- education Section -->
    <section id="education" class="education section light-background">
      <div class="container">

        <!-- education + Summary Titles -->
        <div class="education-header-row">
          <h2 class="education-title">Education</h2>
        </div>

        <div class="education-item">
          <h4><strong>Ph.D. in Computer Science</strong></h4>
          <h5>Fall 2024 - Present</h5>
          <p><em>Missouri University of Science and Technology, MO</em></p>
          <p>Research: Cognitive Workload Assessment, Neuromorphic Computing, Brain Computer Interface</p>
        </div>

        <div class="education-item">
          <h4><strong> Master of Science in Computer Science</strong></h4>
          <h5>Spring 2022 - Spring 2024</h5>
          <p><em>Lamar University, Texas</em></p>
          <p>Course Work: Advanced Operating System, Analysis of Algorithms, Data Science and Big Data Analysis,
            Distributed Computer Systems</p>
        </div>
        <div class="education-item">
          <h4><Strong>BACHELOR OF SCIENCE IN COMPUTER SCIENCE and Engineering</Strong></h4>
          <h5>Spring 2013 - Spring 2018</h5>
          <p><em>BRAC University, Dhaka, Bangladesh</em></p>
          <p>Courses: Numerical Methods, Artifical intelligence, Compiler Design, Intro to Psychology, Computer
            Interfacing, Complex Variables and Laplace Transformations</p>
        </div>
      </div>

      </div>
    </section>



    <!-- experience Section -->
    <section id="experience" class="experience section">
      <div class="container">

        <!-- experience Title -->
        <div class="experience-header-row">
          <h2 class="experience-title">Experience</h2>
        </div>

        <div class="experience-item">
          <h4><strong> Research Assistant</strong></h4>
          <h5><i>Missouri University of Science and Technology (Fall 2024 – Present)</i></h5>
          <ul>
            <li>Developed convolutional spiking neural networks (CSNNs) for classifying cognitive workload.</li>
            <li>Collected and integrated EEG and heart rate variability (HRV) data from experimental tasks.</li>
            <li>Performed preprocessing, signal cleaning, and segmentation for EEG and HRV datasets.</li>
            <li>Extracted features from physiological signals to train and evaluate classification models.</li>

          </ul>
        </div>
        <div class="experience-item">
          <h4><strong> Graduate Assistant</strong></h4>
          <h5><i>Lamar University, Texas (October 2022 – May 2024)</i></h5>
          <ul>
            <li>Analyzed patient transcripts to identify linguistic patterns related to dementia diagnosis.</li>
            <li>Used t-tests and mutual information to select relevant linguistic features.</li>
            <li>Supervised an undergraduate student’s research and co-authored a manuscript.</li>
            <li>Maintained research documentation and submitted progress reports to the department.</li>
          </ul>
        </div>

        <div class="experience-item">
          <h4><strong> Teaching Assistant</strong></h4>
          <h5><i>Lamar University, Texas (May 2023 – May 2024)</i></h5>
          <ul>
            <li>Assisted in course delivery for Distributed Systems, Cloud Computing, Programming Fundamentals III, and
              Data
              Science and Big Data Analysis.</li>
            <li>Graded assignments, exams, and projects based on standardized rubrics.</li>
            <li>Held regular office hours to address student questions and assist with lab work.</li>
            <li>Provided technical support for classroom exercises and coding projects.</li>
            <li>Helped instructors manage learning management system submissions and grading logistics.</li>
          </ul>
        </div>

        <div class="experience-item">
          <h4><strong>Programmer Analyst</strong></h4>
          <h5><i>Dcastalia Limited, Dhaka, Bangladesh (Dec 2018 – Dec 2020)</i></h5>
          <ul>
            <li>Developed websites for clients in education, e-commerce, and training sectors.</li>
            <li>Implemented front-end interfaces and back-end systems using standard web technologies.</li>
            <li>Participated in planning, estimation, and coordination of multiple client projects.</li>
            <li>Tested, debugged, and maintained deployed websites to ensure functionality and uptime.</li>
            <li>Communicated regularly with project managers and clients to meet project requirements.</li>
            <li>Maintained version control using Git and documented all major code changes.</li>
          </ul>
        </div>

      </div>
    </section>

    <!-- Research Seciton Start -->
    <section id="research" class="research section light-background">
      <div class="container">
        <h2 class="research-title">Research</h2>

        <div class="research-simple">
          <div class="research-entry">
            <h4><strong> Cognitive Workload Assessment using Spiking Neural Network</strong></h4>
            <p>
              Assessing and managing workload in <strong>aviation</strong>, <strong>healthcare</strong>,
              <strong>transportation</strong>, and <strong>defense</strong> using synchronized multimodal signals:
              <em>EEG</em>, <em>BCI interfaces</em>, and <em>physiological sensors</em>.
              Tasks include <em>Letter N‑back</em>, <em>Flanker N‑back</em>, and <em>Multiple Object Tracking</em> with
              adjustable
              parameters to model stress and complexity.
              We combine <strong>NASA‑TLX</strong> with objective metrics such as <strong>EEG</strong> and
              <strong>HRV</strong>, and
              apply <strong>machine learning</strong> to classify workload states for real‑time monitoring and error
              prevention.
            </p>

          </div>

          <div class="research-entry">
            <h4><strong>EEG Denoising using Transformer </strong></h4>
            <p>
              EEG often contains <strong>EOG/EMG/ECG</strong> artifacts. Traditional approaches (<em>digital
                filters</em>,
              <em>BSS</em>, <em>WT</em>, <em>EMD</em>) help but can remove neural content or require complex tuning.
              We evaluate deep models—<em>FCNN</em>, <em>RNN</em>, <em>CNN</em>, <em>Complex CNN</em>—and highlight
              their trade‑offs
              (e.g., over‑smoothing, vanishing gradients, limited temporal context, high compute).
              This motivates designing <strong>artifact‑robust architectures</strong> tailored for varying noise
              conditions.
            </p>

          </div>

          <div class="research-entry">
            <h4><strong>Early Stage Dementia Using Natural Language Processing </strong></h4>
            <p>
              Predicting early‑stage dementia from conversational transcripts (e.g., <em>Cookie Theft Picture</em>
              description).
              Using <strong>linguistic features</strong> with <strong>SVM</strong> achieved up to <strong>87.5%</strong>
              (same‑age) and
              <strong>85.26%</strong> (early detection).
              A content‑aware <em>Information Unit</em> feature improves cross‑language robustness; combining
              <em><strong>BoW +
                  IU</strong></em> with
              <strong>logistic regression</strong> reached <strong>88%</strong>.

          </div>

          <div class="research-entry">
            <h4><strong>Inflamed Appendix Detection From Laparoscopic Video Footage using Edge Detection and
                Morphological Image
                Processing.</strong></h4>
            <p>This research was focused to propose an algorithm based on image processing based techniques to detect
              the inflamed appendix.
              These techniques
              include <strong>edge detection, dilation, erosion, and following with bound-boxing.</strong> Given the
              image from the
              laparoscopic video
              footage, our algorithm was designed to<em> <strong> the inflamed appendix from the normal
                  area.</strong></em></p>
          </div>
        </div>
      </div>
    </section>
    <!-- Research Seciton End -->

    <!-- Paper Seciton Start -->
    <section id="paper" class="paper section ">
      <div class="container">
        <h2 class="paper-title">Papers</h2>

        <div class="paper-simple">
          <div class="paper-entry">
            <h4><strong>A Survey on Early-Stage Dementia Detection Using Natural
                Language Processing: Datasets and Approaches</strong></h4>

            <p
              style="font-size: 16px; font-style: italic; color: color-mix(in srgb, var(--default-color), transparent 15%);">
              Asir Abrar, Aetesam Ali Khan Ashar, Jiangjiang Liu
            </p>
            <p style="font-size: 14px;">
              <a href="https://doi.org/10.1145/3686397.3686401" target="_blank"
                style="color: var(--accent-color); text-decoration: underline;">
                https://doi.org/10.1145/3686397.3686401
              </a>
            </p>
            <p>According to the World Health Organization, Dementia, a chronic,
              degenerative condition that affects 55 million people worldwide,
              is prevalent in seniors. To date, there is no cure for dementia, so
              recent advancements in this area emphasize the urgent need for
              detecting early symptoms to facilitate timely intervention strategies. As dementia starts by damaging
              neurons in parts
              of the brain
              responsible for memory, language, and thinking, the analysis of
              language sample could potentially offer a promising avenue for
              detecting subtle cognitive shifts that could allow the possible interventions to slow down the disease’s
              progression and
              improve the
              life of the individuals. We document this paper to explore the potential of leveraging speech and text
              data for
              detecting early-stage
              dementia by leveraging semantic, syntactic, and acoustic features.
              This paper surveys natural language processing (NLP) techniques
              applied to speech, text, audio, and handwritten data in monolingual
              and multilingual settings, focusing on their potential to aid in the
              early detection and understanding of dementia. According to our
              study, most datasets available in this domain are in English, with
              the support vector machine being the most frequently used classification method. Interest is also growing
              in using large
              language
              models to identify the signs of cognitive decline based on language
              patterns.</p>
          </div>

          <div class="paper-entry">
            <h4><strong>Patients' Severity States Classification based on Electronic Health Record (EHR) Data using
                Multiple Machine Learning
                and Deep Learning Approaches</strong></h4>

            <p
              style="font-size: 16px; font-style: italic; color: color-mix(in srgb, var(--default-color), transparent 15%);">
              A. N. M. Sajedul Alam, Rimi Reza, Asir Abrar, Tanvir Ahmed, Salsabil Ahmed, Shihab Sharar, Annajiat Alim
              Rasel
            </p>
            <p style="font-size: 14px;">
              <a href="https://arxiv.org/abs/2209.14907" target="_blank"
                style="color: var(--accent-color); text-decoration: underline;">
                https://arxiv.org/abs/2209.14907
              </a>
            </p>
            <p>This research presents an examination of categorizing the severity states of patients based on their
              electronic health
              records during a certain time range using multiple machine learning and deep learning approaches. The
              suggested method
              uses an EHR dataset collected from an open-source platform to categorize severity. Some tools were used in
              this
              research, such as openRefine was used to pre-process, RapidMiner was used for implementing three
              algorithms (Fast Large
              Margin, Generalized Linear Model, Multi-layer Feed-forward Neural Network) and Tableau was used to
              visualize the data,
              for implementation of algorithms we used Google Colab. Here we implemented several supervised and
              unsupervised
              algorithms along with semi-supervised and deep learning algorithms. The experimental results reveal that
              hyperparameter-tuned Random Forest outperformed all the other supervised machine learning algorithms with
              76% accuracy
              as well as Generalized Linear algorithm achieved the highest precision score 78%, whereas the
              hyperparameter-tuned
              Hierarchical Clustering with 86% precision score and Gaussian Mixture Model with 61% accuracy outperformed
              other
              unsupervised approaches. Dimensionality Reduction improved results a lot for most unsupervised techniques.
              For
              implementing Deep Learning we employed a feed-forward neural network (multi-layer) and the Fast Large
              Margin approach
              for semi-supervised learning. The Fast Large Margin performed really well with a recall score of 84% and
              an F1 score of
              78%. Finally, the Multi-layer Feed-forward Neural Network performed admirably with 75% accuracy, 75%
              precision, 87%
              recall, 81% F1 score.</p>
          </div>

          <div class="paper-entry">
            <h4><strong>A Survey on Deep Learning-based Smart Assistive Aids for
                Visually Impaired Individuals</strong></h4>

            <p
              style="font-size: 16px; font-style: italic; color: color-mix(in srgb, var(--default-color), transparent 15%);">
              Aetesam Ali Khan Ashar, Asir Abrar, Jiangjiang Liu
            </p>
            <p style="font-size: 14px;">
              <a href="https://doi.org/10.1145/3603765.3603775" target="_blank"
                style="color: var(--accent-color); text-decoration: underline;">
                https://doi.org/10.1145/3603765.3603775
              </a>
            </p>
            <p>Visually impaired individuals face significant challenges in interacting with society. However, smart
              canes equipped
              with sensors and
              cameras provide a promising solution for safe navigation. AI-based
              assistive devices, including smart canes, utilize machine learning
              algorithms like YOLO and SSD for object detection and recognition
              through in-built cameras. These devices often employ a standard
              controller and switch for navigation strategy, while sensors such
              as Ultrasonic sensors, I/R Lasers, Rain sensors aid in detecting a
              variety of obstacles such as physical objects or water. With continued research, such technology could
              greatly enhance
              the visually
              impaired person’s ability to interact with their surroundings and
              potentially even travel independently.</p>
          </div>

          <div class="paper-entry">
            <h4><strong>A Survey on Object Detection and Recognition for Blurred and Low-Quality Images: Handling,
                Deblurring,
                and
                Reconstruction</strong></h4>

            <p
              style="font-size: 16px; font-style: italic; color: color-mix(in srgb, var(--default-color), transparent 15%);">
              Aetesam Ali Khan Ashar, Asir Abrar, Jiangjiang Liu
            </p>
            <p style="font-size: 14px;">
              <a href="https://doi.org/10.1145/3686397.3686413" target="_blank"
                style="color: var(--accent-color); text-decoration: underline;">
                https://doi.org/10.1145/3686397.3686413
              </a>
            </p>
            <p>Object detection and recognition in blurred and low-quality images present significant challenges in
              computer vision and
              image processing. This survey paper provides a comprehensive overview of the state-of-the-art techniques,
              methodologies,
              and advancements in addressing these challenges. Blurred and low-quality images are encountered in various
              real-world
              scenarios, such as surveillance, medical imaging, and autonomous vehicles, making robust object detection
              and
              recognition essential. This paper reviews the key issues, datasets, evaluation metrics, and recent
              advancements in this
              field, with an emphasis on deep learning-based approaches. Particular emphasis is placed on the
              integration of popular
              object detection models such as SSD (Single Shot Multibox Detector), COCO (Common Objects in Context), and
              YOLO (You
              Only Look Once) with deblurring techniques. Through this survey, we aim to provide researchers and
              practitioners with
              valuable insights into the current landscape of object detection and recognition in challenging imaging
              conditions,
              facilitating further research and application development in this critical domain.</p>
          </div>
          <div class="paper-entry">
            <h4><strong>WIP: A Reconfigurable Testbed for Assessing Cognitive
                Workload in N-back and Multiple Object Tracking Tasks *</strong></h4>

            <p
              style="font-size: 16px; font-style: italic; color: color-mix(in srgb, var(--default-color), transparent 15%);">
              Yug Patel, Sanjana Shangle, Asir Abrar, Venkata Sriram Siddhardh Nadendla, K.
              Krishnamurthy
            </p>

            <p>Cognitive workload assessment and management are critical in managing work efficiency in highstress
              environments and
              long-duration tasks, such as critical infrastructure operations, first-responder
              responses, healthcare, military, and transportation. A major challenge in developing cognitive
              assessment algorithms lies in designing an experimental testbed that integrates diverse systems
              like brain-computer interfaces, physiological sensors, and task-specific hardware for synchronized
              multi-modal data collection. This paper presents a novel reconfigurable testbed for assessing cognitive
              workload using
              Letter N-back, Flanker N-back, and multiple object tracking (MOT) tasks.
              The testbed features customizable parameters such as trial length, difficulty level, and task complexity,
              allowing
              simulation of various stress levels. The integration of Neuroelectrics EEG headsets and Bluetooth-enabled
              physiological
              sensors ensures real-time multimodal data acquisition.
              In addition, the modular design supports future expansion for new tasks and devices, fostering
              advancements in cognitive neuroscience and human performance research.</p>
          </div>
          <div class="paper-entry">
            <h4><strong>Inflamed Appendix Detection from Laparoscopic
                Video Footage Using Edge Detection and
                Morphological Image Processing
                <p
                  style="font-size: 16px; font-style: italic; color: color-mix(in srgb, var(--default-color), transparent 15%);">
                  S H Tashfeen, Asir Abrar, Tasmia Taslim Tondra
                </p>

                <p>In the world of surgical instruments laparoscopy has a vital space. Laparoscopic surgery is
                  also called minimally invasive surgery technique where operations are performed through
                  small incision elsewhere in the body. Laparoscopic appendectomy is one kind of surgery in
                  which doctors perform the operation manually through small incision by looking at the
                  monitor. In this study a new approach has been proposed, so that the machine can automatically
                  detect the appendix, by using edge detection and morphological image processing techniques.
                  In order to implement the proposed model a laparoscopic appendectomy video footage has
                  been taken under consideration and every frame of the footage has been separated. After the
                  frame separation process the proposed algorithm has been applied in every frame. It has been
                  observed that the proposed algorithm is robust enough to detect the ROI from frames that
                  contains noise.</p>
          </div>
        </div>
      </div>
    </section>
    <!-- Paper Seciton End -->



    <!-- Other Project Start -->
    <section id="paper" class="paper section light-background">
      <div class="container">
        <h2 class="paper-title">Other Projects</h2>

        <div class="paper-simple">
          <div class="paper-entry">
            <h4><strong>Automated Traffic Monitoring System using Arduino Uno and VLP , and Character
                Recognition using
                Morphological Image
                Processing and Template Matching Technique</strong></h4>
            <p>We constructed a model to build an effective traffic monitoring system, especially in rainy seasons
              depending on
              electrical sensors and vehicle license plates. Firstly, we developed a prototype using LDRsensors and
              Arduino UNO to
              reduce the electricity consumption in the street light. Secondly, moisture sensors along with
              microcontrollers and servo
              motors were used to prevent traffic jams in the water-clogging situation. Then, a sonar sensor was
              integrated with a
              micro-controller to ensure a buzzer if any vehicle violates traffic rules. And finally, by morphological
              image
              processing technique, we extracted the information from the license plates.</p>
          </div>

          <div class="paper-entry">
            <h4><strong>A Survey on Deep Learning-based Smart Assistive Aids for
                Visually Impaired Individuals</strong> </h4>
            <p>Visually impaired individuals face significant challenges in interacting with society. However, smart
              canes equipped
              with sensors and
              cameras provide a promising solution for safe navigation. AI-based
              assistive devices, including smart canes, utilize machine learning
              algorithms like YOLO and SSD for object detection and recognition
              through in-built cameras. These devices often employ a standard
              controller and switch for navigation strategy, while sensors such
              as Ultrasonic sensors, I/R Lasers, Rain sensors aid in detecting a
              variety of obstacles such as physical objects or water. With continued research, such technology could
              greatly enhance
              the visually
              impaired person’s ability to interact with their surroundings and
              potentially even travel independently.</p>
          </div>

          <div class="paper-entry">
            <h4><strong>BRAC E-Education Website</strong></h4>
            <p>A Website for the student and the teachers where primary to secondary learning materials are available
              for easy access.
              Finding the requirements, maintaining the communication to develop the website, uploading on the server
              and
              troubleshooting was my task.</p>
          </div>
          <div class="paper-entry">
            <h4><strong>Spectra Inventory Management System</strong></h4>
            <p>Inventory management system where all the data required for building, road, and bridge construction were
              stored. From
              the very beginning, my engagement was to analyze the requirement, identify the future scope, testing the
              project, and
              propose the solution while maintaining communication as well.</p>
          </div>
        </div>
      </div>
    </section>
    <!-- Other Project Seciton End -->

    <!-- Award Seciton Start -->
    <section id="award" class="award section">
      <div class="container">
        <h2 class="award-title">Awards</h2>

        <div class="award-simple">
          <div class="award-entry">
            <ul>
              <li>Outstanding Graduate Student 2024</li>
              <li>Outstanding Mentor Award - CS SUCCESS 2024</li>
              <li>Outstanding Mentor Award - CS SUCCESS 2023</li>
              <li>Table Tennis (1st Place - U1250, San Antonio 2022)</li>
            </ul>
          </div>



        </div>
      </div>
    </section>

    <!--Award Section End-->


    <!-- footer start -->


    <footer id="footer" class="footer position-relative light-background">
      <div class="container">
        <div class="row gy-4 text-center text-md-start align-items-center">

          <div class="col-md-3">
            <div class="info-item d-flex justify-content-center justify-content-md-start">
              <i class="bi bi-geo-alt flex-shrink-0"></i>
              <div>
                <h4>Address</h4>
                <p>2321 Lanes End Ln, Rolla, MO-65401</p>
              </div>
            </div>
          </div>

          <div class="col-md-3">
            <div class="info-item d-flex justify-content-center justify-content-md-start">
              <i class="bi bi-telephone flex-shrink-0"></i>
              <div>
                <h4>Phone</h4>
                <p>+1 (945) 217-2798</p>
              </div>
            </div>
          </div>

          <div class="col-md-3">
            <div class="info-item d-flex justify-content-center justify-content-md-start">
              <i class="bi bi-envelope flex-shrink-0"></i>
              <div>
                <h4>Email</h4>
                <p>aa8zz@umsystem.edu</p>
              </div>
            </div>
          </div>

          <div class="col-md-3">
            <div class="social-links">
              <a href="https://linkedin.com/in/asir-abrar" class="linkedin"><i class="bi bi-linkedin"></i></a>
              <a href="https://github.com/asirabrarragib/" class="github"><i class="bi bi-github"></i></a>
              <a href="https://www.facebook.com/asir.ragib/" class="facebook"><i class="bi bi-facebook"></i></a>
              <a href="https://www.instagram.com/asir_ragib_ragib/" class="instagram"><i
                  class="bi bi-instagram"></i></a>
              <a href="https://scholar.google.com/citations?user=vbrO0IcAAAAJ" class="googlescholar"><i
                  class="fa-brands fa-google-scholar"></i></a>

            </div>
          </div>

          <div class="col-12 text-center copyright">
            <p>© Copyright <strong class="px-1 sitename">AsirAbrar</strong> All Rights Reserved</p>
          </div>
        </div>
      </div>
    </footer>


    <!-- footer End -->

    <!-- Scroll Top -->
    <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i
        class="bi bi-arrow-up-short"></i></a>

    <!-- Preloader -->
    <div id="preloader"></div>

    <!-- Vendor JS Files -->
    <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <script src="assets/vendor/php-email-form/validate.js"></script>
    <script src="assets/vendor/aos/aos.js"></script>
    <script src="assets/vendor/typed.js/typed.umd.js"></script>
    <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
    <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
    <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
    <script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
    <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
    <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

    <!-- Main JS File -->
    <script src="assets/js/main.js"></script>

</body>

</html>